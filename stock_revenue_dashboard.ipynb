{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e035db",
   "metadata": {},
   "source": [
    "# Peer-graded Assignment: Analyzing Historical Stock/Revenue Data and Building a Dashboard\n",
    "\n",
    "**Student**: Mk  \n",
    "**Date**: 2025-06-13\n",
    "\n",
    "This notebook extracts historical stock and revenue data for Tesla (TSLA) and GameStop (GME), displays key snapshots, and builds an interactive dashboard to visualize price and revenue trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d767cc2",
   "metadata": {},
   "source": [
    "## Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27219db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (0.2.63)\n",
      "Requirement already satisfied: requests in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (2.32.4)\n",
      "Requirement already satisfied: bs4 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: plotly in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (6.1.2)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from yfinance) (2.3.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from yfinance) (6.31.1)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from yfinance) (0.11.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from yfinance) (2.2.6)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from yfinance) (2025.2)\n",
      "Requirement already satisfied: websockets>=13.0 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from yfinance) (15.0.1)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from yfinance) (3.18.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from yfinance) (4.13.4)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from yfinance) (4.3.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: packaging in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from plotly) (25.0)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from plotly) (1.42.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.14.0)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mriga\\onedrive - the university of texas at dallas\\misc\\coursera\\ibm_datascience\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance requests bs4 plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b4410c",
   "metadata": {},
   "source": [
    "## Question 1: Use yfinance to Extract Tesla Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "819a63bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla Stock Data (first 5 rows):\n",
      "                       Date      Open      High       Low     Close  \\\n",
      "0 2010-06-29 00:00:00-04:00  1.266667  1.666667  1.169333  1.592667   \n",
      "1 2010-06-30 00:00:00-04:00  1.719333  2.028000  1.553333  1.588667   \n",
      "2 2010-07-01 00:00:00-04:00  1.666667  1.728000  1.351333  1.464000   \n",
      "3 2010-07-02 00:00:00-04:00  1.533333  1.540000  1.247333  1.280000   \n",
      "4 2010-07-06 00:00:00-04:00  1.333333  1.333333  1.055333  1.074000   \n",
      "\n",
      "      Volume  Dividends  Stock Splits  \n",
      "0  281494500        0.0           0.0  \n",
      "1  257806500        0.0           0.0  \n",
      "2  123282000        0.0           0.0  \n",
      "3   77097000        0.0           0.0  \n",
      "4  103003500        0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Create ticker object and fetch historical data\n",
    "tesla = yf.Ticker(\"TSLA\")\n",
    "tesla_data = tesla.history(period=\"max\")\n",
    "\n",
    "# Reset index and display first five rows\n",
    "tesla_data.reset_index(inplace=True)\n",
    "print(\"Tesla Stock Data (first 5 rows):\")\n",
    "print(tesla_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250dd210",
   "metadata": {},
   "source": [
    "## Question 2: Use Webscraping to Extract Tesla Revenue Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c3d3a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Use pandas to grab the “Tesla Quarterly Revenue” table directly\u001b[39;00m\n\u001b[0;32m      6\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.macrotrends.net/stocks/charts/TSLA/tesla/revenue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m tables \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTesla Quarterly Revenue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# The first matching table is our revenue data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m tesla_revenue \u001b[38;5;241m=\u001b[39m tables[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\mriga\\OneDrive - The University of Texas at Dallas\\Misc\\Coursera\\IBM_DataScience\\.venv\\lib\\site-packages\\pandas\\io\\html.py:1240\u001b[0m, in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[0m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1225\u001b[0m     [\n\u001b[0;32m   1226\u001b[0m         is_file_like(io),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1230\u001b[0m     ]\n\u001b[0;32m   1231\u001b[0m ):\n\u001b[0;32m   1232\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal html to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_html\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1234\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[1;32m-> 1240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mriga\\OneDrive - The University of Texas at Dallas\\Misc\\Coursera\\IBM_DataScience\\.venv\\lib\\site-packages\\pandas\\io\\html.py:983\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    972\u001b[0m p \u001b[38;5;241m=\u001b[39m parser(\n\u001b[0;32m    973\u001b[0m     io,\n\u001b[0;32m    974\u001b[0m     compiled_match,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    979\u001b[0m     storage_options,\n\u001b[0;32m    980\u001b[0m )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 983\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[0;32m    986\u001b[0m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io\u001b[38;5;241m.\u001b[39mseekable():\n",
      "File \u001b[1;32mc:\\Users\\mriga\\OneDrive - The University of Texas at Dallas\\Misc\\Coursera\\IBM_DataScience\\.venv\\lib\\site-packages\\pandas\\io\\html.py:249\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    242\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_tables(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs)\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "File \u001b[1;32mc:\\Users\\mriga\\OneDrive - The University of Texas at Dallas\\Misc\\Coursera\\IBM_DataScience\\.venv\\lib\\site-packages\\pandas\\io\\html.py:806\u001b[0m, in \u001b[0;36m_LxmlFrameParser._build_doc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    804\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 806\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(r, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_content\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\mriga\\OneDrive - The University of Texas at Dallas\\Misc\\Coursera\\IBM_DataScience\\.venv\\lib\\site-packages\\pandas\\io\\html.py:785\u001b[0m, in \u001b[0;36m_LxmlFrameParser._build_doc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio):\n\u001b[1;32m--> 785\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    788\u001b[0m             r \u001b[38;5;241m=\u001b[39m parse(f\u001b[38;5;241m.\u001b[39mhandle, parser\u001b[38;5;241m=\u001b[39mparser)\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# try to parse the input in the simplest way\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mriga\\OneDrive - The University of Texas at Dallas\\Misc\\Coursera\\IBM_DataScience\\.venv\\lib\\site-packages\\pandas\\io\\common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32mc:\\Users\\mriga\\OneDrive - The University of Texas at Dallas\\Misc\\Coursera\\IBM_DataScience\\.venv\\lib\\site-packages\\pandas\\io\\common.py:384\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[0;32m    383\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[1;32m--> 384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[0;32m    385\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mriga\\OneDrive - The University of Texas at Dallas\\Misc\\Coursera\\IBM_DataScience\\.venv\\lib\\site-packages\\pandas\\io\\common.py:289\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "# Question 2: Use Webscraping to Extract Tesla Revenue Data (with headers + pd.read_html)\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.macrotrends.net/stocks/charts/TSLA/tesla/revenue\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "resp = requests.get(url, headers=headers)\n",
    "\n",
    "# Parse all tables from the fetched HTML\n",
    "tables = pd.read_html(resp.text)\n",
    "\n",
    "# Find the one with exactly two columns (Date & Revenue)\n",
    "for df in tables:\n",
    "    if df.shape[1] == 2:\n",
    "        tesla_revenue = df.copy()\n",
    "        break\n",
    "\n",
    "# Rename, clean and convert\n",
    "tesla_revenue.columns = [\"Date\", \"Revenue\"]\n",
    "tesla_revenue[\"Revenue\"] = (\n",
    "    tesla_revenue[\"Revenue\"]\n",
    "    .str.replace(r\"[\\$,]\", \"\", regex=True)\n",
    "    .astype(int)\n",
    ")\n",
    "tesla_revenue[\"Date\"] = pd.to_datetime(tesla_revenue[\"Date\"])\n",
    "\n",
    "# Show last 5 rows\n",
    "print(\"Tesla Revenue Data (last 5 rows):\")\n",
    "print(tesla_revenue.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e79080",
   "metadata": {},
   "source": [
    "## Question 3: Use yfinance to Extract GameStop Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2920df9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ticker object and fetch historical data for GameStop\n",
    "gme = yf.Ticker(\"GME\")\n",
    "gme_data = gme.history(period=\"max\")\n",
    "\n",
    "# Reset index and display first five rows\n",
    "gme_data.reset_index(inplace=True)\n",
    "print(\"GameStop Stock Data (first 5 rows):\")\n",
    "print(gme_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bcdb5c",
   "metadata": {},
   "source": [
    "## Question 4: Use Webscraping to Extract GameStop Revenue Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f2edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape GameStop quarterly revenue from Macrotrends\n",
    "url = \"https://www.macrotrends.net/stocks/charts/GME/gamestop/revenue\"\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Locate and parse the revenue table\n",
    "tables = soup.find_all(\"table\")\n",
    "for table in tables:\n",
    "    if \"GameStop Quarterly Revenue\" in table.text:\n",
    "        revenue_table = table\n",
    "        break\n",
    "\n",
    "gme_rev_rows = revenue_table.find_all(\"tr\")[1:]\n",
    "rows = []\n",
    "for row in gme_rev_rows:\n",
    "    cols = row.find_all(\"td\")\n",
    "    if len(cols) >= 2:\n",
    "        date = cols[0].text.strip()\n",
    "        revenue = cols[1].text.strip().replace(\"$\", \"\").replace(\",\", \"\")\n",
    "        if revenue:\n",
    "            rows.append([date, int(revenue)])\n",
    "gme_revenue = pd.DataFrame(rows, columns=[\"Date\", \"Revenue\"])\n",
    "gme_revenue[\"Date\"] = pd.to_datetime(gme_revenue[\"Date\"])\n",
    "\n",
    "print(\"GameStop Revenue Data (last 5 rows):\")\n",
    "print(gme_revenue.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2573492d",
   "metadata": {},
   "source": [
    "## Question 5 & 6: Plot Stock and Revenue Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eafb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Function to build interactive dashboard\n",
    "def make_graph(stock_df, revenue_df, title):\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        subplot_titles=(f\"{title} Stock Price\", f\"{title} Revenue\"),\n",
    "        vertical_spacing=0.2\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=stock_df[\"Date\"], y=stock_df[\"Close\"], name=\"Close Price\"),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.update_xaxes(rangeslider_visible=True, row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Price ($US)\", row=1, col=1)\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=revenue_df[\"Date\"], y=revenue_df[\"Revenue\"], name=\"Revenue\"),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Revenue ($US Millions)\", row=2, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f\"{title} Historical Stock Price and Revenue\",\n",
    "        height=800\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# Plot for Tesla\n",
    "make_graph(tesla_data, tesla_revenue, \"Tesla\")\n",
    "# Plot for GameStop\n",
    "make_graph(gme_data, gme_revenue, \"GameStop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e46cc3a",
   "metadata": {},
   "source": [
    "## Assignment Repository Link\n",
    "\n",
    "[GitHub Repository](https://github.com/mrigankmaharana/IBM_PythonProjectforDataScience)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
